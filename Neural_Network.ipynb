{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98144abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72669f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3873504301.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    def forward()(self,x):\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "#create a Model class that is inherits neural network nn.Module\n",
    "class Model(nn.Module):\n",
    "    #input layer with 4 features of flower from our datasets --> \n",
    "    #choose to hidden Layer1(H1)(number of neurons in it)--> H2(n)--> \n",
    "    #output (3classes of flower)\n",
    "    def __init__(self, in_features=4, h1=8,h2=9,OutputLayers=3):\n",
    "        super().__init__() #instantiate our nn.module\n",
    "        #fully connect \n",
    "        self.fc1=nn.Linear(in_features,h1)\n",
    "        self.fc2=nn.Linear(h1,h2)\n",
    "        self.out=nn.Linear(h2,OutputLayers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #rectified linear unit\n",
    "        #start to layer one then move to layer 2\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c81108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a manual seed for randomization\n",
    "torch.manual_seed(32)\n",
    "# Create an instance of model\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821b41f-b469-46e5-b8ae-dd3c5e6a9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "#data frame\n",
    "my_df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf7fad-bdd5-4439-9380-45141667e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f052e-e32e-4f24-a5b7-8f7f78c7a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5b3fe-bc60-4716-a474-013af7361fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the last column from string to int\n",
    "#my_df['variety']=my_df['variety'].replace('Setos',0.0)\n",
    "#my_df['variety']=my_df['variety'].replace('Versicolor',1.0)\n",
    "#my_df['variety']=my_df['variety'].replace('Virginica',2.0)\n",
    "\n",
    "my_df['variety'] = my_df['variety'].replace({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\n",
    "# Handle future downcasting\n",
    "my_df = my_df.infer_objects(copy=False)\n",
    "# Split features and labels\n",
    "X = my_df.drop('variety', axis=1)\n",
    "#train test and split set X,Y\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde7fe-be49-49b8-9a49-0078e6e810d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert its datatype to int64 (64-bit integer)\n",
    "y = my_df['variety'].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf97e8f-03eb-4610-af5a-abb8a918813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert these to numpy arrays\n",
    "X= X.values\n",
    "y= y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d86372-179a-4964-84cf-bf175b24918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996cbd4-9d11-4854-a27e-8b97a1eca00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train test split testsize 20%, Train size is 80%\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d583a8-caec-480b-ae21-53d05baab7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947fee7-dea9-4b92-ad9d-9ccfb9c299ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Y features to Long tensors\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557ba00-9bee-4880-bc70-a479bbe72bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the criterion of model to measure the error, how far off the predictions are from the data\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "#choose Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs), lower learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672edda-ba2a-4553-8da0-ee3d1014b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model\n",
    "# Epochs?(one run thru all the training data in our network), current we set spin 100 time\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train) #get predicted results\n",
    "\n",
    "    # We want to measure the loss/error, it will be high at first\n",
    "    loss = criterion(y_pred, y_train) #predicted values vs the y_train\n",
    "\n",
    "    #keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "    #print every 10 epochs\n",
    "    if i%10==0:\n",
    "        print(f'epochs:{i} and loss: {loss}')\n",
    "\n",
    "    #do some back propogation by take the error rate of forward propagation and feed it back\n",
    "    #thru the network to fine tune the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1aef99-6efa-47f4-a119-de8ff36929ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph the plot\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"Validation Loss/error\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73d062-5583-4925-bd5d-de5aed909af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Data Set (Validate model on test set)\n",
    "with torch.no_grad(): #turn off back propogation\n",
    "    y_eval = model.forward(X_test) # X_test are features from out test set, y_eval wil be predictions\n",
    "    loss = criterion(y_eval,y_test) # Find the loss or error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359229c3-0447-4057-8456-180ec71e08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26a9db-9912-4096-ba04-8f211337d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val= model.forward(data)\n",
    "\n",
    "        if y_test[i]==0:\n",
    "            x=\"Setsosa\"\n",
    "        elif y_test[i]==1:\n",
    "            x=\"Versicolor\"\n",
    "        else:\n",
    "            x=\"Virginica\"\n",
    "            \n",
    "        print(f'{i+1}.) {str(y_val)} \\t{x} \\t {y_val.argmax().item()}')\n",
    "\n",
    "        #let find out if this result is correct or not\n",
    "        if y_val.argmax().item() ==y_test[i]:\n",
    "            correct +=1\n",
    "print(f'We got the result {correct} predicted correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ebc6f-3457-4dea-ad8b-0d37c023c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed new data\n",
    "new_iris= torch.tensor([4.7, 3.2, 1.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c40e92-154c-4d62-bea8-8b43b457e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(new_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3de49-2cf1-4884-be79-b76dc17a7dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c7af3-3119-4e85-ba83-c14d1dc332b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a750a62-e384-4673-aa20-ccd0049c2e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f500fc7-c13d-4883-af56-763c53ddd5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93daf47-cb8d-4f47-8d99-8974c259a529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9038b4-d257-4e24-bbff-fce6b52cb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
